# Machine Learning with PySpark MLlib

## Introduction
Apache Spark is known as a fast, easy-to-use and general engine for big data processing that has built-in modules for streaming, SQL, Machine Learning (ML) and graph processing. This technology is an in-demand skill for data engineers, but also data scientists can benefit from learning Spark when doing Exploratory Data Analysis (EDA), feature extraction and, of course, ML.


In-Memory computation and Parallel-Processing are some of the major reasons that Apache Spark has become very popular in the big data industry to deal with data products at large scale and perform faster analysis. built on top of Spark, MLlib is a scalable Machine Learning library that delivers both high-quality algorithms and blazing speed. 


## Machine Learning Library (MLlib)

- Data types
- Basic statistics
    - summary statistics
    - correlations
    - stratified sampling
    - hypothesis testing
    - random data generation
- Classification and regression
    - linear models (SVMs, logistic regression, linear regression)
    - naive Bayes
    - decision trees
    - ensembles of trees (Random Forests and Gradient-Boosted Trees)
- Collaborative filtering
    - alternating least squares (ALS)
- Clustering
    - k-means
- Dimensionality reduction
    - singular value decomposition (SVD)
    - principal component analysis (PCA)
- Feature extraction and transformation
- Optimization (developer)
    - stochastic gradient descent
    - limited-memory BFGS (L-BFGS)
